{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMQA20zhLqFE"
      },
      "source": [
        "DGM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7zUoUeUqLqkt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from models.mart import MART\n",
        "from types import SimpleNamespace\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UloXQoOTrZqc",
        "outputId": "7b45777f-7dbc-430d-803b-aa8bf6f6477d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 13 15:25:01 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCwSBeGjrZtk",
        "outputId": "86039c8d-501e-421b-9814-97d5486a5ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.1.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m680.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.0%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0+cu118) (2024.10.0)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0+cu118)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.0+cu118) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.0+cu118) (2.32.3)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install torch==2.1.0+cu118 and torchvision==0.15.0+cu118 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested torch==2.1.0+cu118\n",
            "    torchvision 0.15.0+cu118 depends on torch==2.0.0+cu118\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the correct version of PyTorch with GPU support\n",
        "!pip install torch==2.1.0+cu118 torchvision==0.15.0+cu118 torchaudio==2.1.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1gaK_3NrZ1s",
        "outputId": "d38c46ff-52b3-4f0d-880f-6ccaf75a66f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Br_xJHpZQRdK"
      },
      "outputs": [],
      "source": [
        "def load_config(config_path):\n",
        "    \"\"\"\n",
        "    Load configuration from a YAML file.\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to the YAML configuration file.\n",
        "\n",
        "    Returns:\n",
        "        dict: Loaded configuration dictionary.\n",
        "    \"\"\"\n",
        "    print(f\"[INFO] Loading configuration from {config_path}...\")\n",
        "    with open(config_path, 'r') as file:\n",
        "        config = yaml.safe_load(file)\n",
        "    print(\"[INFO] Configuration loaded successfully!\")\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sxPMfQnFOZGt"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_PATH = \"files/sdd_ckpt_best.pth\"  # Update this\n",
        "TEST_DATA_PATH = \"files/sdd_test.pkl\"  # Update this\n",
        "CONFIG_PATH = \"files/mart_sdd_reproduce.yaml\"  # Update this\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-5qkGgs0OcFi"
      },
      "outputs": [],
      "source": [
        "def load_model(checkpoint_path, opts):\n",
        "    print(\"[INFO] Loading model from checkpoint...\")\n",
        "    args = SimpleNamespace(**opts)\n",
        "    model = MART(args)  # Remove .cuda()\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=True)\n",
        "\n",
        "\n",
        "    model.load_state_dict(checkpoint['state_dict'])  # or whatever loading method you are using\n",
        "\n",
        "    print(\"[INFO] Model loaded successfully!\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hA8PRR6LOf6g"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, opts):\n",
        "    print(\"[INFO] Starting evaluation...\")\n",
        "    ade_sum, fde_sum, total_agents = 0.0, 0.0, 0\n",
        "\n",
        "    # Set the device to GPU or CPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)  # Move model to device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sample in test_loader:\n",
        "            x_abs, y = sample\n",
        "            x_abs, y = x_abs.to(device), y.to(device)  # Move tensors to device\n",
        "\n",
        "            batch_size, num_agents, length, _ = x_abs.size()\n",
        "\n",
        "            x_rel = torch.zeros_like(x_abs).to(device)  # Ensure x_rel is on the same device\n",
        "            x_rel[:, :, 1:] = x_abs[:, :, 1:] - x_abs[:, :, :-1]\n",
        "            x_rel[:, :, 0] = x_rel[:, :, 1]\n",
        "\n",
        "            y_pred = model(x_abs, x_rel)\n",
        "\n",
        "            if opts[\"pred_rel\"]:\n",
        "                cur_pos = x_abs[:, :, [-1]].unsqueeze(2)\n",
        "                y_pred = torch.cumsum(y_pred, dim=3) + cur_pos\n",
        "\n",
        "            ade = torch.min(torch.mean(torch.norm(y_pred - y[:, :, None], dim=-1), dim=3), dim=2)[0].mean().item()\n",
        "            fde = torch.min(torch.mean(torch.norm(y_pred[:, :, :, -1:] - y[:, :, None, -1:], dim=-1), dim=3), dim=2)[0].mean().item()\n",
        "\n",
        "            ade_sum += ade * num_agents * batch_size\n",
        "            fde_sum += fde * num_agents * batch_size\n",
        "            total_agents += num_agents * batch_size\n",
        "\n",
        "    ade_avg = (ade_sum / total_agents) * opts[\"scale\"]\n",
        "    fde_avg = (fde_sum / total_agents) * opts[\"scale\"]\n",
        "\n",
        "    print(f\"[INFO] Evaluation Results: ADE = {ade_avg:.4f}, FDE = {fde_avg:.4f}\")\n",
        "    return ade_avg, fde_avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gFU-woSrfBKJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class TrajectoryDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, obs_len=8, pred_len=12, mode='train', scale=10, inputs=None, max_agents=50\n",
        "    ):\n",
        "        super(TrajectoryDataset, self).__init__()\n",
        "\n",
        "        self.obs_len = obs_len\n",
        "        self.pred_len = pred_len\n",
        "        self.seq_len = self.obs_len + self.pred_len\n",
        "        self.scale = scale\n",
        "        self.max_agents = max_agents\n",
        "\n",
        "        with open('files/sdd_test.pkl'.format(mode), 'rb') as f:\n",
        "            traj = pickle.load(f)\n",
        "\n",
        "        traj_tmp = []\n",
        "\n",
        "        for t in traj:\n",
        "            traj_tmp.append(t)\n",
        "            if mode == 'train':\n",
        "                traj_tmp.append(np.flip(t, axis=1))\n",
        "\n",
        "        self.traj = []\n",
        "        if 'pos_x' in inputs and 'pos_y' in inputs:\n",
        "            for t in traj_tmp:\n",
        "                t -= t[:, :1, :]\n",
        "                self.traj.append(t)\n",
        "        else:\n",
        "            self.traj = traj_tmp\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.traj)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        past_traj = self.traj[index][:, :self.obs_len] * self.scale\n",
        "        future_traj = self.traj[index][:, self.obs_len:] * self.scale\n",
        "\n",
        "        # Padding the number of agents to max_agents if necessary\n",
        "        num_agents = past_traj.shape[0]\n",
        "        if num_agents < self.max_agents:\n",
        "            pad_size = self.max_agents - num_agents\n",
        "            past_traj_padded = np.pad(past_traj, ((0, pad_size), (0, 0), (0, 0)), mode='constant')\n",
        "            future_traj_padded = np.pad(future_traj, ((0, pad_size), (0, 0), (0, 0)), mode='constant')\n",
        "        else:\n",
        "            past_traj_padded = past_traj\n",
        "            future_traj_padded = future_traj\n",
        "\n",
        "        past_traj = torch.from_numpy(past_traj_padded).type(torch.float)\n",
        "        future_traj = torch.from_numpy(future_traj_padded).type(torch.float)\n",
        "\n",
        "        return [past_traj, future_traj]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6LvJHV2Oavo",
        "outputId": "f2eedda6-3ef4-462e-907d-22f8d24ed5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading configuration from files/mart_sdd_reproduce.yaml...\n",
            "[INFO] Configuration loaded successfully!\n",
            "[INFO] Loading model from checkpoint...\n",
            "[INFO] PRT Agg: cat\n",
            "[INFO] HRT Agg: avg\n",
            "[INFO] Binary Threshold Function Type: 2\n",
            "[INFO] Model loaded successfully!\n",
            "[INFO] Starting evaluation with test data...\n",
            "[INFO] Starting evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Evaluation Results: ADE = 0.7582, FDE = 1.2163\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "if __name__ == \"__main__\":\n",
        "    opts = load_config(CONFIG_PATH)\n",
        "    model = load_model(CHECKPOINT_PATH, opts)\n",
        "\n",
        "    # Prepare the test dataset and DataLoader\n",
        "    test_dataset = TrajectoryDataset(\n",
        "        obs_len=opts[\"past_length\"],\n",
        "        pred_len=opts[\"future_length\"],\n",
        "        mode=\"test\",  # This loads the test set\n",
        "        scale=opts[\"scale\"],\n",
        "        inputs=opts[\"inputs\"]\n",
        "    )\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "    print(\"[INFO] Starting evaluation with test data...\")\n",
        "    evaluate_model(model, test_loader, opts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from copy import deepcopy\n",
        "from collections import OrderedDict\n",
        "import yaml\n",
        "from types import SimpleNamespace\n",
        "from dataloader_eth import TrajectoryDataset, seq_collate  # Ensure this module is correctly implemented"
      ],
      "metadata": {
        "id": "KnJUGYUzvj7B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model configuration\n",
        "with open('files/mart_sdd_reproduce.yaml', 'r') as file:\n",
        "    config_dict = yaml.safe_load(file)"
      ],
      "metadata": {
        "id": "wLu9rPWvvrlX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the config dictionary to an object with attributes\n",
        "config = SimpleNamespace(**config_dict)\n"
      ],
      "metadata": {
        "id": "5tfSIJ2Hvt1I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the base model is loaded from the SDD checkpoint\n",
        "from models.mart import MART  # Ensure this import is correct\n",
        "\n",
        "def load_model(checkpoint_path, opts):\n",
        "    print(\"[INFO] Loading model from checkpoint...\")\n",
        "    args = opts  # Directly use the SimpleNamespace without unpacking\n",
        "    model = MART(args)\n",
        "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    print(\"[INFO] Model loaded successfully!\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "JVe1W7uUvzFb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"files/sdd_ckpt_best.pth\"  # Ensure this path is correct\n",
        "base_model = load_model(CHECKPOINT_PATH, config)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "base_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN4wJo9gv1YR",
        "outputId": "16fcbc54-1df3-4b43-d169-1756b1faa82b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading model from checkpoint...\n",
            "[INFO] PRT Agg: cat\n",
            "[INFO] HRT Agg: avg\n",
            "[INFO] Binary Threshold Function Type: 2\n",
            "[INFO] Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-acd099bf873f>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MART(\n",
              "  (input_fc): Linear(in_features=2, out_features=64, bias=True)\n",
              "  (input_fc2): Linear(in_features=512, out_features=64, bias=True)\n",
              "  (pos_encoder): PositionalAgentEncoding(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              "  (pair_encoders): ModuleList(\n",
              "    (0): RT(\n",
              "      (layers): ModuleList(\n",
              "        (0): RTTransformerLayer(\n",
              "          (attention_layer): RTAttentionLayer(\n",
              "            (proj_qkv_n): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_qkv_e): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_o): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (linear_net_n): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear_net1_e): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear_net2_e): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (node2edge_mlp): MLP(\n",
              "        (layers): ModuleList(\n",
              "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
              "        )\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (1-3): 3 x RTNoEdgeInit(\n",
              "      (layers): ModuleList(\n",
              "        (0): RTTransformerLayer(\n",
              "          (attention_layer): RTAttentionLayer(\n",
              "            (proj_qkv_n): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_qkv_e): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_o): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (linear_net_n): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear_net1_e): Sequential(\n",
              "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear_net2_e): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (hyper_encoders): ModuleList(\n",
              "    (0): HRT(\n",
              "      (layers): ModuleList(\n",
              "        (0): HRTTransformerLayer(\n",
              "          (node_attention_layer): HRTAttentionLayer(\n",
              "            (proj_qkv_n): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_qkv_e): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_o): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (linear_net_n): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear_net1_e): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear_net2_e): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (node2edge_mlp): MLP(\n",
              "        (layers): ModuleList(\n",
              "          (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
              "        )\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (group_gen): AdaptiveGroupEstimator(\n",
              "        (ste): BinaryThreshold()\n",
              "      )\n",
              "    )\n",
              "    (1-3): 3 x HRTNoEdgeInit(\n",
              "      (layers): ModuleList(\n",
              "        (0): HRTTransformerLayer(\n",
              "          (node_attention_layer): HRTAttentionLayer(\n",
              "            (proj_qkv_n): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_qkv_e): Linear(in_features=64, out_features=192, bias=True)\n",
              "            (proj_o): Linear(in_features=64, out_features=64, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (linear_net_n): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_n): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (linear_net1_e): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (linear_net2_e): Sequential(\n",
              "            (0): Linear(in_features=64, out_features=128, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "          )\n",
              "          (norm1_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2_e): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_0): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_1): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_2): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_3): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_4): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_5): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_6): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_7): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_8): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_9): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_10): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_11): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_12): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_13): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_14): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_15): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_16): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_17): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_18): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (head_19): Decoder(\n",
              "    (decoder_mlp): MLP(\n",
              "      (layers): Sequential(\n",
              "        (0): Linear(in_features=192, out_features=128, bias=True)\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Linear(in_features=64, out_features=24, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define datasets for ETH-UCY\n",
        "datasets = {\n",
        "    'eth': 'Data/eth',\n",
        "    'hotel': 'Data/hotel',\n",
        "    'univ': 'Data/uni',\n",
        "    'zara1': 'Data/zara1',\n",
        "    'zara2': 'Data/zara2',\n",
        "}"
      ],
      "metadata": {
        "id": "59GAjTFywlpG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data loaders for each subset\n",
        "data_loaders = {}\n",
        "for subset, path in datasets.items():\n",
        "    dataset = TrajectoryDataset(\n",
        "        args=config,\n",
        "        data_dir=path,\n",
        "        obs_len=config.past_length,\n",
        "        pred_len=config.future_length,\n",
        "        delim='\\t',\n",
        "    )\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=config.batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=seq_collate,\n",
        "        num_workers=4,  # Adjust based on your system\n",
        "    )\n",
        "    data_loaders[subset] = loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OmwsuuIwoaz",
        "outputId": "e0bfd1a3-0cd1-4413-ac7d-253a970ae193"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:00<00:00, 879.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [00:00<00:00, 979.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 188/188 [00:00<00:00, 1234.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 602/602 [00:00<00:00, 975.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Data .....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 561/561 [00:00<00:00, 879.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(model, data_loader, optimizer, criterion, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for batch in data_loader:\n",
        "            # Ensure that 'past_traj' and 'future_traj' are keys returned by seq_collate\n",
        "            inputs = batch['past_traj'].to(device)  # Shape: [batch_size, num_agents, obs_len, 2]\n",
        "            targets = batch['future_traj'].to(device)  # Shape: [batch_size, num_agents, pred_len, 2]\n",
        "\n",
        "            # Compute relative positions if required by the model\n",
        "            x_rel = torch.zeros_like(inputs).to(device)\n",
        "            x_rel[:, :, 1:] = inputs[:, :, 1:] - inputs[:, :, :-1]\n",
        "            x_rel[:, :, 0] = x_rel[:, :, 1]\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs, x_rel)  # Adjust if your model requires different inputs\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(data_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
        "    return deepcopy(model.state_dict())"
      ],
      "metadata": {
        "id": "dsx_miblyXvr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_weights(weight_list):\n",
        "    avg_weights = OrderedDict()\n",
        "    for key in weight_list[0].keys():\n",
        "        # Stack weights for the current key from all models and compute the mean\n",
        "        avg_weights[key] = torch.mean(torch.stack([weights[key] for weights in weight_list]), dim=0)\n",
        "    return avg_weights"
      ],
      "metadata": {
        "id": "Y7gQxWwrybJO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_weights = []\n",
        "\n",
        "# Fine-tune on each subset separately\n",
        "for subset_name, data_loader in data_loaders.items():\n",
        "    print(f\"\\nFine-tuning on subset: {subset_name}\")\n",
        "    # Create a fresh copy of the base model for each subset\n",
        "    model_copy = deepcopy(base_model)\n",
        "    model_copy.to(device)\n",
        "\n",
        "    # Define a separate optimizer for each model copy\n",
        "    optimizer = torch.optim.Adam(model_copy.parameters(), lr=config.lr)\n",
        "\n",
        "    # Define the loss criterion\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Fine-tune the model copy on the current subset\n",
        "    state_dict = fine_tune_model(model_copy, data_loader, optimizer, criterion, num_epochs=config.num_epochs)\n",
        "\n",
        "    # Collect the fine-tuned weights\n",
        "    fine_tuned_weights.append(state_dict)\n",
        "    print(f\"Finished fine-tuning on subset: {subset_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "2yBkeho7yeqH",
        "outputId": "7ff4b481-bd3e-4cc8-f750-047c90ed4ae8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine-tuning on subset: eth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/content/dataloader_eth.py\", line 15, in seq_collate\n    past_traj = torch.stack(past_traj,dim=0)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 8, 2] at entry 0 and [2, 8, 2] at entry 1\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-df4d1dcf81a8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Fine-tune the model copy on the current subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfine_tune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Collect the fine-tuned weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f5cff8e3cc54>\u001b[0m in \u001b[0;36mfine_tune_model\u001b[0;34m(model, data_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;31m# Ensure that 'past_traj' and 'future_traj' are keys returned by seq_collate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'past_traj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: [batch_size, num_agents, obs_len, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/content/dataloader_eth.py\", line 15, in seq_collate\n    past_traj = torch.stack(past_traj,dim=0)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 8, 2] at entry 0 and [2, 8, 2] at entry 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AeWsc5AAtCh0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "526b73fa-afbc-4a17-dec3-8bcb958dec3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Averaging weights from all fine-tuned models...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2bce6b71c9f2>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Perform weight averaging across all fine-tuned models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAveraging weights from all fine-tuned models...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mfinal_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfine_tuned_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Load the averaged weights into the base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-2bce6b71c9f2>\u001b[0m in \u001b[0;36maverage_weights\u001b[0;34m(weight_list)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maverage_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mavg_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Stack weights for the current key from all models and compute the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mavg_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweight_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Perform weight averaging across all fine-tuned models\n",
        "print(\"\\nAveraging weights from all fine-tuned models...\")\n",
        "final_weights = average_weights(fine_tuned_weights)\n",
        "\n",
        "# Load the averaged weights into the base model\n",
        "base_model.load_state_dict(final_weights)\n",
        "\n",
        "# Save the fine-tuned and averaged model\n",
        "torch.save({'model_state_dict': base_model.state_dict()}, 'files/eth_ucy_finetuned.pth')\n",
        "print(\"[INFO] Fine-tuned model saved successfully at 'files/eth_ucy_finetuned.pth'.\")\n",
        "\n",
        "# Optional: Evaluate the fine-tuned model for robustness\n",
        "def evaluate_finetuned_model(model, test_loader, opts):\n",
        "    print(\"[INFO] Starting evaluation of the fine-tuned model...\")\n",
        "    ade_sum, fde_sum, total_agents = 0.0, 0.0, 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for sample in test_loader:\n",
        "            x_abs, y = sample\n",
        "            x_abs, y = x_abs.to(device), y.to(device)\n",
        "\n",
        "            batch_size, num_agents, length, _ = x_abs.size()\n",
        "\n",
        "            x_rel = torch.zeros_like(x_abs).to(device)\n",
        "            x_rel[:, :, 1:] = x_abs[:, :, 1:] - x_abs[:, :, :-1]\n",
        "            x_rel[:, :, 0] = x_rel[:, :, 1]\n",
        "\n",
        "            y_pred = model(x_abs, x_rel)\n",
        "\n",
        "            if opts.pred_rel:\n",
        "                cur_pos = x_abs[:, :, [-1]].unsqueeze(2)\n",
        "                y_pred = torch.cumsum(y_pred, dim=3) + cur_pos\n",
        "\n",
        "            ade = torch.min(torch.mean(torch.norm(y_pred - y[:, :, None], dim=-1), dim=3), dim=2)[0].mean().item()\n",
        "            fde = torch.min(torch.mean(torch.norm(y_pred[:, :, :, -1:] - y[:, :, None, -1:], dim=-1), dim=3), dim=2)[0].mean().item()\n",
        "\n",
        "            ade_sum += ade * num_agents * batch_size\n",
        "            fde_sum += fde * num_agents * batch_size\n",
        "            total_agents += num_agents * batch_size\n",
        "\n",
        "    ade_avg = (ade_sum / total_agents) * opts.scale\n",
        "    fde_avg = (fde_sum / total_agents) * opts.scale\n",
        "\n",
        "    print(f\"[INFO] Fine-Tuned Model Evaluation Results: ADE = {ade_avg:.4f}, FDE = {fde_avg:.4f}\")\n",
        "    return ade_avg, fde_avg\n",
        "\n",
        "# Assuming you have a test set for ETH-UCY, prepare the test DataLoader\n",
        "# Update the path and parameters as needed\n",
        "test_dataset = TrajectoryDataset(\n",
        "    args=config,\n",
        "    data_dir='Data/eth_ucy_test.txt',  # Update with actual test data path\n",
        "    obs_len=config.past_length,\n",
        "    pred_len=config.future_length,\n",
        "    delim='\\t',\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=seq_collate,\n",
        "    num_workers=4,\n",
        ")\n",
        "\n",
        "# Evaluate the fine-tuned model\n",
        "evaluate_finetuned_model(base_model, test_loader, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I9bRCBadwqrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}